version: '3.7'

# ====================================== AIRFLOW ENVIRONMENT VARIABLES =======================================
x-environment: &airflow_environment
  - AIRFLOW__CORE__EXECUTOR=LocalExecutor
  - AIRFLOW__CORE__FERNET_KEY=hCRoPUYBO27QiEg1MRu5hSjLG7yNd8y8XKlm-8kRlkQ=
  - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
  - AIRFLOW__CORE__LOAD_EXAMPLES=False
  - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://airflow:airflow@postgres:5432/airflow
  - AIRFLOW__CORE__STORE_DAG_CODE=True
  - AIRFLOW__CORE__STORE_SERIALIZED_DAGS=True
  - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=30
  - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
  - AIRFLOW__WEBSERVER__RBAC=True
# ====================================== /AIRFLOW ENVIRONMENT VARIABLES ======================================

services:
  postgres:
    image: postgres:13-alpine
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"

  initdb_adduser:
    image: apache/airflow:1.10.11-python3.7
    depends_on:
      - postgres
    environment: *airflow_environment
    entrypoint: /bin/bash
    # The webserver initializes permissions, so sleep for that to (approximately) be finished
    # No disaster if the webserver isn't finished by then, but create_user will start spitting out errors until the permissions exist
    command: -c 'airflow initdb && sleep 5 && airflow create_user --role Admin --username airflow --password airflow -e airflow@airflow.com -f airflow -l airflow'

  webserver:
    image: apache/airflow:1.10.11-python3.7
    restart: always
    depends_on:
      - postgres
    volumes:
      - logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    environment: *airflow_environment
    command: webserver

  scheduler:
    image: apache/airflow:1.10.11-python3.7
    restart: always
    depends_on:
      - postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/testing_examples/src
      - ./setup.py:/opt/airflow/testing_examples/setup.py
      - logs:/opt/airflow/logs
    environment: *airflow_environment
    entrypoint: ["/bin/sh"]
    command: ["-c", "pip install --user -e /opt/airflow/testing_examples && airflow scheduler"]

volumes:
  logs:
